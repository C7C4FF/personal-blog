---
layout: post
title: "0613 크롤링 정리"
subtitle: "크롤링 코드 정리"
date: 2020-06-13 13:00:00 +0900
background: '/img/posts/06.jpg'
categories: ['programming', 'python']
---

# 0613

진행 중... 리스트로 받아오기

- [x]  cast 에서 "출연 : " 을 기점으로 분리하기
- [x]  DataFrame으로 잘 출력 되게 하기
- [x]  해결 ^^7

```python
from selenium import webdriver
import pandas as pd
import time

driver = webdriver.Chrome('/Users/beom/Documents/chromedriver')
driver.get("http://www.playdb.co.kr/playdb/playdblist.asp?sReqMainCategory=000001&sReqSubCategory=&sReqDistrict=&sReqTab=2&sPlayType=1&sStartYear=2019&sSelectType=3")

def page(pagevalue):
    pages = driver.find_element_by_xpath('//*[@id="contents"]/div[2]/table/tbody/tr[11]/td/table/tbody/tr[35]/td/a['+str(pagevalue)+']')
    pages.click()

def crawling():
    alist = []
    for i in range(1, 16):
        j = 1 + (i * 2)
        title = driver.find_element_by_xpath('//*[@id="contents"]/div[2]/table/tbody/tr[11]/td/table/tbody/tr['+str(j)+']/td/table/tbody/tr/td[1]/table/tbody/tr/td[3]/table/tbody/tr[1]/td/b/font/a')
        loca = driver.find_element_by_xpath('//*[@id="contents"]/div[2]/table/tbody/tr[11]/td/table/tbody/tr['+str(j)+']/td/table/tbody/tr/td[1]/table/tbody/tr/td[3]/table/tbody/tr[2]/td/a[1]')
        cast = driver.find_element_by_xpath('//*[@id="contents"]/div[2]/table/tbody/tr[11]/td/table/tbody/tr['+str(j)+']/td/table/tbody/tr/td[1]/table/tbody/tr/td[3]/table/tbody/tr[2]/td')
        alist.append([title.text, loca.text, cast.text])
        print(alist)

for n in range(2):
    p = n + 1
    url = driver.current_url
    driver.get(url)
    time.sleep(2)
    crawling()
    page(int(p))

result = pd.DataFrame(alist, columns=['뮤지컬명', '장소', '캐스팅'])
result.index = result.index + 1
result.head()
```

```python
from selenium import webdriver
import pandas as pd
import time

driver = webdriver.Chrome('/Users/kohyerim/Selenium/chromedriver')
driver.get(
    "http://www.playdb.co.kr/playdb/playdblist.asp?sReqMainCategory=000001&sReqSubCategory=&sReqDistrict=&sReqTab=2&sPlayType=1&sStartYear=2019&sSelectType=3")

def page(pagevalue):
    pages = driver.find_element_by_xpath(
        '//*[@id="contents"]/div[2]/table/tbody/tr[11]/td/table/tbody/tr[35]/td/a[' + str(pagevalue) + ']')
    pages.click()

def crawling():
    alist = []
    for i in range(1, 16):
        j = 1 + (i * 2)
        title = driver.find_element_by_xpath('//*[@id="contents"]/div[2]/table/tbody/tr[11]/td/table/tbody/tr[' + str(
            j) + ']/td/table/tbody/tr/td[1]/table/tbody/tr/td[3]/table/tbody/tr[1]/td/b/font/a')
        loca = driver.find_element_by_xpath('//*[@id="contents"]/div[2]/table/tbody/tr[11]/td/table/tbody/tr[' + str(
            j) + ']/td/table/tbody/tr/td[1]/table/tbody/tr/td[3]/table/tbody/tr[2]/td/a[1]')

				# 수정한 부분 시작
        tmp = driver.find_element_by_xpath('//*[@id="contents"]/div[2]/table/tbody/tr[11]/td/table/tbody/tr[' + str(
            j) + ']/td/table/tbody/tr/td[1]/table/tbody/tr/td[3]/table/tbody/tr[2]/td')
        genre = tmp.text.split("\n")[0]
        date = tmp.text.split("\n")[1]
        location = tmp.text.split("\n")[2]
        cast = tmp.text.split("\n")[3]
        staff = tmp.text.split("\n")[4]
        # split example : ['세부장르 : 창작', '일시 : 2019.07.06 ~ 2019.10.20', '장소 : 대학로 티오엠 1관', '출연 : 정문성, 정동화, 김경수, 주민진, 안유진, 정연, 최연우, 최수진, 김재범, 정민, 에녹, 김종구', 'Staff : 성종완, 김은영']
        alist.append([title.text, loca.text, cast])
    return alist
		# 수정한 부분 끝

for n in range(2):
    p = n + 1
    url = driver.current_url
    driver.get(url)
    time.sleep(2)
    alist = crawling()  # 수정한 부분
    page(int(p))

# print(alist)
result = pd.DataFrame(alist, columns=['뮤지컬명', '장소', '캐스팅'])
result.index = result.index + 1
print(result.head()) # 주피터면 print 굳이 안해도 되는데 저는 파이참으로 해서 걍 print한 것임..
```
